environment:
  python_requirements_txt: requirements.txt
inputs:
  chat_history:
    default: []
    is_chat_history: true
    is_chat_input: false
    type: list
  customerId:
    default: '2'
    is_chat_history: false
    is_chat_input: false
    type: string
  question:
    default: What can you tell me about your jackets?
    is_chat_history: false
    is_chat_input: true
    type: string
nodes:
- inputs:
    connection: bge-large
    deployment_name: bge-large-en-v1.5
    question: ${inputs.question}
  name: custom_question_embedding
  source:
    path: custom_embedding.py
    type: code
  type: python
- inputs:
    embedding: ${custom_question_embedding.output}
    index_name: contoso-products
    question: ${inputs.question}
    search: contoso-search
  name: retrieve_documentation
  source:
    path: retrieve_documentation.py
    type: code
  type: python
- inputs:
    conn: contoso-cosmos
    customerId: ${inputs.customerId}
  name: customer_lookup
  source:
    path: customer_lookup.py
    type: code
  type: python
- inputs:
    customer: ${customer_lookup.output}
    documentation: ${retrieve_documentation.output}
    history: ${inputs.chat_history}
  name: customer_prompt
  source:
    path: customer_prompt.jinja2
    type: code
  type: prompt
- api: chat
  connection: meta_llama3_instruct_70B
  inputs:
    deployment_name: gpt-35-turbo
    prompt_text: ${customer_prompt.output}
    question: ${inputs.question}
    top_p: 0.9
  name: llm_response
  source:
    path: llm_response.jinja2
    type: code
  type: llm
outputs:
  answer:
    is_chat_output: true
    reference: ${llm_response.output}
    type: string
  context:
    is_chat_output: false
    reference: ${retrieve_documentation.output}
    type: string
